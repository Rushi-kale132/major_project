{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5s8anbmHNv2wRBpSdBpX1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rushi-kale132/major_project/blob/main/major.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLdHceGWWpge",
        "outputId": "4c3dc4e6-a784-4e5b-db1d-e1118351364c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/archive.zip, /content/archive.zip.zip or /content/archive.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip /content/archive.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "\n",
        "# Define U-Net architecture\n",
        "def unet(pretrained_weights=None, input_size=(256, 256, 1)):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
        "        UpSampling2D(size=(2, 2))(drop5))\n",
        "    merge6 = concatenate([drop4, up6], axis=3)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
        "        UpSampling2D(size=(2, 2))(conv6))\n",
        "    merge7 = concatenate([conv3, up7], axis=3)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
        "        UpSampling2D(size=(2, 2))(conv7))\n",
        "    merge8 = concatenate([conv2, up8], axis=3)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
        "        UpSampling2D(size=(2, 2))(conv8))\n",
        "    merge9 = concatenate([conv1, up9], axis=3)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=1e-4), loss\n",
        "                  = 'binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Print the model summary\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Load the pre-trained U-Net model\n",
        "unet_model = unet()\n",
        "\n",
        "# Define paths to your liver segmentation dataset\n",
        "train_images_path = '/content/3DIRCADB/train/Images'\n",
        "train_masks_path = '/content/3DIRCADB/train/Masks'\n",
        "val_images_path = '/content/3DIRCADB/test/Images'\n",
        "val_masks_path = '/content/3DIRCADB/test/Masks'\n",
        "\n",
        "# Define data generators for training and validation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_image_generator = train_datagen.flow_from_directory(\n",
        "    train_images_path,\n",
        "    target_size=(256, 256),\n",
        "    color_mode='grayscale',\n",
        "    class_mode=None,\n",
        "    batch_size=8,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "train_mask_generator = train_datagen.flow_from_directory(\n",
        "    train_masks_path,\n",
        "    target_size=(256, 256),\n",
        "    color_mode='grayscale',\n",
        "    class_mode=None,\n",
        "    batch_size=8,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "val_image_generator = val_datagen.flow_from_directory(\n",
        "    val_images_path,\n",
        "    target_size=(256, 256),\n",
        "    color_mode='grayscale',\n",
        "    class_mode=None,\n",
        "    batch_size=8,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "val_mask_generator = val_datagen.flow_from_directory(\n",
        "    val_masks_path,\n",
        "    target_size=(256, 256),\n",
        "    color_mode='grayscale',\n",
        "    class_mode=None,\n",
        "    batch_size=8,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "train_generator = zip(train_image_generator, train_mask_generator)\n",
        "val_generator = zip(val_image_generator, val_mask_generator)\n",
        "\n",
        "# Train the model\n",
        "unet_model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_image_generator),\n",
        "    epochs=20,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(val_image_generator)\n",
        ")"
      ],
      "metadata": {
        "id": "bKTcNDADXBMQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}